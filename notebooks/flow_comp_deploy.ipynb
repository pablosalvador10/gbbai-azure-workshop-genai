{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, load_component, Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from promptflow import PFClient\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from azure.ai.ml.entities import Data, AmlCompute, BatchEndpoint, PipelineComponentBatchDeployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victor-aml\n",
      "https://victor-aoai.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# authenticate\n",
    "credential = DefaultAzureCredential(tenantid=os.environ.get('TENANT_ID'))\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id = os.environ.get('SUBSCRIPTION_ID'),\n",
    "    resource_group_name = os.environ.get('RESOURCE_GROUP_NAME'),\n",
    "    workspace_name = os.environ.get('WORKSPACE_NAME'),\n",
    ")\n",
    "\n",
    "print(os.getenv(\"WORKSPACE_NAME\"))\n",
    "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config parameters\n",
    "\n",
    "# PFClient can help manage your runs and connections.\n",
    "pf = PFClient()\n",
    "\n",
    "# Define Flows and Data\n",
    "grey_customer_data = Input(path=\"../sample_data/sample_chat_outputs/grey_tests_customer.json\", type='uri_file')\n",
    "grey_grader_data = Input(path=\"../sample_data/sample_chat_outputs/grey_tests_grader.json\", type='uri_file')\n",
    "red_test_data = Input(path=\"../sample_data/sample_chat_outputs/red_tests.json\", type='uri_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_cust_component = load_component(\"../src/components/evaluation_framework/promptflow/eval_flows/grey_eval_customer/flow.dag.yaml\")\n",
    "grey_grader_component = load_component(\"../src/components/evaluation_framework/promptflow/eval_flows/grey_eval_grader/flow.dag.yaml\")\n",
    "red_test_component = load_component(\"../src/components/evaluation_framework/promptflow/eval_flows/red_eval/flow.dag.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: gray_scooter_38frkt78xt\n",
      "Web View: https://ml.azure.com/runs/gray_scooter_38frkt78xt?wsid=/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/victor-rg/workspaces/victor-aml\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-03-18 20:28:33Z] Submitting 3 runs, first five are: 6a62dd92:74baf96b-0f6f-4aa4-9878-2cdcd01fd46f,73fa00ff:a4d9f316-30d9-4241-916f-0e5917844c65,8391981c:ef246fa0-a541-4517-94e1-d59b46c1ba69\n",
      "[2024-03-18 20:44:44Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: gray_scooter_38frkt78xt\n",
      "Web View: https://ml.azure.com/runs/gray_scooter_38frkt78xt?wsid=/subscriptions/9a729243-1221-42c5-824c-9e44cb2da98d/resourcegroups/victor-rg/workspaces/victor-aml\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /grey_cust_flow, /red_test_flow, /grey_grader_flow. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"centralus\",\n    \"location\": \"centralus\",\n    \"time\": \"2024-03-18T20:44:44.207Z\",\n    \"component_name\": \"\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m pipeline_with_flow\u001b[38;5;241m.\u001b[39mcompute \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu-target\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mcreate_or_update(pipeline_with_flow)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_wkshp/lib/python3.9/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_wkshp/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:285\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    283\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    284\u001b[0m         ):\n\u001b[0;32m--> 285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_wkshp/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:813\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_wkshp/lib/python3.9/site-packages/azure/ai/ml/operations/_job_ops_helper.py:332\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    330\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    333\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[1;32m    334\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    335\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    336\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    337\u001b[0m         )\n\u001b[1;32m    339\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /grey_cust_flow, /red_test_flow, /grey_grader_flow. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"centralus\",\n    \"location\": \"centralus\",\n    \"time\": \"2024-03-18T20:44:44.207Z\",\n    \"component_name\": \"\"\n} "
     ]
    }
   ],
   "source": [
    "@pipeline\n",
    "def pipeline_func_with_flow(grey_cust_input, grey_grader_input, red_test_input):\n",
    "    grey_cust_flow = grey_cust_component(\n",
    "        data=grey_cust_input,\n",
    "        generated_question = \"${grey_cust_input.generated_question}\"\n",
    "    )\n",
    "\n",
    "    grey_grader_flow = grey_grader_component(\n",
    "        data=grey_grader_input,\n",
    "        generated_question = \"${grey_grader_input.generated_question}\",\n",
    "        gt_response = \"${grey_grader_input.ground_truth_response}\",\n",
    "        user_response = \"${grey_grader_input.user_response}\",\n",
    "        evaluation = \"${grey_grader_input.evaluation}\",\n",
    "        evaluation_score = \"${grey_grader_input.evaluation_score}\"\n",
    "    )\n",
    "\n",
    "    red_test_flow = red_test_component(\n",
    "        data=red_test_input,\n",
    "        user_input=\"${red_test_input.user_response}\",\n",
    "        chat_response=\"${red_test_input.chat_response}\"\n",
    "    )\n",
    "\n",
    "pipeline_with_flow = pipeline_func_with_flow(grey_customer_data, grey_grader_data, red_test_data)\n",
    "pipeline_with_flow.compute = \"cpu-target\"\n",
    "\n",
    "pipeline_job = ml_client.jobs.create_or_update(pipeline_with_flow)\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_wkshp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
